# -*- coding: utf-8 -*-
"""Image_Colorization_GANson.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NI8NPZXOuyqvLCemOWABGHqnrpgRb-Ds

# Image Colorization Using CGAN

## Steps followed

#### 1. Importing Necessary Libraries
#### 2. Fetching The Dataset and Setting Up Input Paths
#### 3. Defining Train and Test DataLoaders¶
#### 4. Modeling the Conditional GAN
#### 5. Defining Helper Functions
#### 6. Initializing The Model
#### 7. Training
#### 8. Visualizing Loss Trajectory
#### 9. Visualizing Predictions

## Step 1. Importing necessary libraries and Setting Device
"""

import torch
import torchvision
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torch import nn, optim

import numpy as np
import glob
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gs
from matplotlib import font_manager as fm, rcParams
from PIL import Image
from skimage.color import rgb2lab, lab2rgb

from tqdm import tqdm

from datetime import datetime

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

"""## Step 2. Fetching The Dataset and Setting Up Input Paths

### Installing fastai for Quickly Getting The COCO Dataset
"""

!pip install -U fastai
import fastai

from google.colab import drive
drive.mount('/content/drive')

"""### Grabbing The Dataset in the Following Directory Structure
<pre>
.
└── .fastai
    └── data
        └── coco_sample
            └── train_sample
                └── *.jpg (10,000 images in total)</pre>
"""

data_path = "/content/drive/MyDrive"
data_path = str(data_path) + "/train_sample"
paths = glob.glob(data_path + "/*.jpg")
# Setting seed for getting the same data across all train sessions 
np.random.seed(123)
paths_subset = np.random.choice(paths, 4_700, replace=False) # choosing 4700 images randomly
rand_idxs = np.random.permutation(4_700)
train_idxs = rand_idxs[:4_700] # choosing the first 4000 as training set
val_idxs = rand_idxs[4_700:] # choosing last 700 as validation set
train_paths = paths_subset[train_idxs]
val_paths = paths_subset[val_idxs]
print(train_paths)

"""### Previewing The Input Images"""

imageCount = 0
fig, ax = plt.subplots(4, 4, figsize=(13,13))
for i in range(4):
    for j in range(4):    
        ax[i, j].imshow(Image.open(train_paths[imageCount]))
        imageCount+=1

"""## Step 3. Defining Train and Test DataLoaders"""

ImageSize = 256
class MakeDataset(Dataset):
    def __init__(self, paths):
        self.transforms = transforms.Compose([
                transforms.Resize((ImageSize, ImageSize),  transforms.InterpolationMode.BICUBIC),
                transforms.RandomHorizontalFlip(), # Added after 350th Epoch to see if Results improves
            ])
        self.paths=paths

    def __getitem__(self, i):
        img = Image.open(self.paths[i])
        img = img.convert("RGB")
        img = self.transforms(img)
        img = np.array(img)
        imgInLAB = rgb2lab(img).astype("float32")
        imgInLAB = transforms.ToTensor()(imgInLAB)
        L_array = imgInLAB[[0], ...] / 50. - 1.
        ab_array = imgInLAB[[1, 2], ...] / 110.
        return [L_array, ab_array]
        
    def __len__(self):
        return len(self.paths)

"""#### Making dataloaders with input images transformed to L and ab image space, after resizing to 256x256"""

BatchSize, Workers = [16, 4]
trainDL = DataLoader(MakeDataset(paths=train_paths), batch_size=BatchSize, num_workers=Workers, pin_memory=True, shuffle = True)
validationDL = DataLoader(MakeDataset(paths=val_paths), batch_size=BatchSize, num_workers=Workers, pin_memory=True, shuffle = True)

"""#### Looking at the Transformed Data

##### Helper Function for Converting a batch of Lab images into a batch of RGB images
"""

def lab_to_rgb(L, ab):  
    L = (L + 1.) * 50.
    ab = ab * 110.
    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()
    rgb_imgs = []
    for img in Lab:
        img_rgb = lab2rgb(img)
        rgb_imgs.append(img_rgb)
    return np.stack(rgb_imgs, axis=0)

data = next(iter(trainDL))
L_Array, ab_Array = data[0], data[1]
print(f"L Array Shape : {L_Array.shape}", f"*a*b Array Shape : {ab_Array.shape}",sep='\n')

fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(15,10))
ax0.imshow(L_Array[0][0], cmap='gray')
ax0.set_title('L')
ax1.imshow(ab_Array[0][0])
ax1.set_title('a')
ax2.imshow(ab_Array[0][1])
ax2.set_title('b')
ax3.imshow(lab_to_rgb(L_Array,ab_Array)[0])
ax3.set_title('RGB')
plt.show()

"""## Step 4. Modeling the Conditional GAN

### Generator Model
"""

class GenBlock(nn.Module):
    def __init__(self, inputs, outputs, down=True, batchNorm=True, dropout=False):
        super(GenBlock,self).__init__()

        if down:
            self.block1 = nn.Conv2d(inputs, outputs, kernel_size=4, stride=2, padding=1, bias=False)
            self.block4 = nn.LeakyReLU(0.2, True)
        else:
            self.block1 = nn.ConvTranspose2d(inputs, outputs, kernel_size=4, stride=2, padding=1, bias=False)
            self.block4 = nn.ReLU(True)
        if batchNorm:
            self.block2 = nn.BatchNorm2d(outputs)
        if dropout:
            self.block3 = nn.Dropout(0.5)

        self.batchNorm = batchNorm
        self.dropout = dropout
    
    def forward(self, x):
        out = self.block1(x)
        if self.batchNorm:
            out = self.block2(out)
        if self.dropout:
            out = self.block3(out)
        out = self.block4(out)
        return out

class Generator(nn.Module):
    def __init__(self, inputs=1):
        super(Generator,self).__init__()
        
        self.d1=  GenBlock(inputs,64,batchNorm=False)
        self.d2=  GenBlock(64,128)
        self.d3=  GenBlock(128,256)
        self.d4=  GenBlock(256,512)
        self.d5=  GenBlock(512,512)
        self.d6=  GenBlock(512,512)
        self.d7=  GenBlock(512,512)
        self.d8=  nn.Sequential(nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=False), nn.LeakyReLU(0.2))
        
        
        self.u1 = GenBlock(512,512,False,dropout=True)
        self.u2 = GenBlock(1024,512,False,dropout=True)
        self.u3 = GenBlock(1024,512,False,dropout=True)
        self.u4 = GenBlock(1024,512,False)
        self.u5 = GenBlock(1024,256,False)
        self.u6 = GenBlock(512,128,False)
        self.u7 = GenBlock(256,64,False)
        self.u8 = nn.Sequential(nn.ConvTranspose2d(128, 2, kernel_size=4, stride=2, padding=1, bias=False), nn.Tanh())
        
    
    def forward(self, x):
        dd1 = self.d1(x)
        dd2 = self.d2(dd1)
        dd3 = self.d3(dd2)
        dd4 = self.d4(dd3)
        dd5 = self.d5(dd4)
        dd6 = self.d6(dd5)
        dd7 = self.d7(dd6)
        dd8 = self.d8(dd7)
        uu1 = self.u1(dd8)
        uu2 = self.u2(torch.concat([uu1,dd7],1)) #Skip Connection from dd7 to uu1
        uu3 = self.u3(torch.concat([uu2,dd6],1))
        uu4 = self.u4(torch.concat([uu3,dd5],1))
        uu5 = self.u5(torch.concat([uu4,dd4],1))
        uu6 = self.u6(torch.concat([uu5,dd3],1))
        uu7 = self.u7(torch.concat([uu6,dd2],1))
        uu8 = self.u8(torch.concat([uu7,dd1],1))
        return uu8

"""#### Generator Model Summary"""

!pip install -U torchsummary
from torchsummary import summary

testGenerator=Generator(1)
summary(testGenerator,(1,ImageSize,ImageSize),batch_size=BatchSize,device="cpu")

"""### Discriminator Model"""

class DiscBlock(nn.Module):
    def __init__(self, inputs, outputs,  kernel=4, stride=2, padding=1, batchNorm=True, activation=True):
        super(DiscBlock,self).__init__()
        
        self.block1 = nn.Conv2d(inputs, outputs, kernel, stride, padding, bias=not batchNorm)
        if batchNorm: self.block2 = nn.BatchNorm2d(outputs)
        if activation: self.block3 = nn.LeakyReLU(0.2, True)

        self.batchNorm = batchNorm
        self.activation = activation


    def forward(self, x):
        out = self.block1(x)
        if self.batchNorm:
            out = self.block2(out)
        if self.activation:
            out = self.block3(out)
        # print(out.shape)
        return out
        

class Discriminator(nn.Module):
    def __init__(self, inputs=3):
        super(Discriminator,self).__init__()

        self.b1 = DiscBlock(inputs,64,batchNorm=False)
        self.b2 = DiscBlock(64,128)
        self.b3 = DiscBlock(128,256)
        self.b4 = DiscBlock(256,512,stride=1)
        self.b5 = DiscBlock(512,1,stride=1,batchNorm=False,activation=False)
                                
    def forward(self, x):
        #print(x.shape())
        y1 = self.b1(x)
        y2 = self.b2(y1)
        y3 = self.b3(y2)
        y4 = self.b4(y3)
        y5 = self.b5(y4)
        return y5

"""#### Discriminator Model Summary"""

testDiscriminator=Discriminator(3)
summary(testDiscriminator,(3,ImageSize,ImageSize),batch_size=BatchSize,device="cpu")

"""## Step 5. Defining Helper Functions

#### For Generating Some Predictions
"""

def ShowSamples(Model, dl, folder='./', epoch= -1, SAVE = True,suffix=""):
    data = next(iter(dl))
    L, ab = data[0], data[1]
    L=L.to(device)
    ab=ab.to(device)
    #Setting Model to Evaluation Mode. This disables layers like dropout
    Model.eval()
    with torch.no_grad():
        abGenerated = Model(L)
    Model.train()
    inputImages = lab_to_rgb(L, ab)
    generatedImages = lab_to_rgb(L, abGenerated)
    row,col,img = 1,3,5  #Row = Number of samples generated per run (Keep it smaller than ${BatchSize}, Col=constant, img = Image size.
    fig = plt.figure(figsize=(col*img, row*img))
    gs1 = gs.GridSpec(nrows=row,ncols=col)
    for i in range(row):
        ax = plt.subplot(gs1[i,0])
        ax.imshow(L[i][0].cpu(), cmap='gray')
        ax.axis("off")
        ax.set_title('Grayscale',fontsize=16, fontweight='bold')
        ax = plt.subplot(gs1[i,1])
        ax.imshow(generatedImages[i])
        ax.axis("off")
        ax.set_title('Prediction',fontsize=16, fontweight='bold')
        ax = plt.subplot(gs1[i,2])
        ax.imshow(inputImages[i])
        ax.axis("off")
        ax.set_title('Ground Truth',fontsize=16, fontweight='bold') 
        
    plt.subplots_adjust(wspace=0, hspace=0.1)
    plt.show()
    
    if SAVE:
        now = datetime.now()
        currentTime = now.strftime("%H:%M:%S")
        fig.savefig(folder + f"/Results_After_Epoch_{epoch}{suffix}_{currentTime}.png")

# ShowSamples(gen, validationDL,SAVE=False, suffix="_On_Validation_set")

"""#### For Visualizing Loss"""

def VisualizeLoss(lossArr, folder, epoch, generator = True, SAVE = True):
    x=(range(0,len(lossArr)))
    plt.figure(figsize = (12,10))
    plt.plot(x,lossArr)
    str = "Discriminator"
    if generator:
        str = "Generator"
        
    plt.xlabel("Number of Iterations")
    plt.ylabel(str + " Loss")
    if SAVE:
        now = datetime.now()
        currentTime = now.strftime("%H:%M:%S")
        plt.savefig(folder + f"/{str}_Loss_After_Epoch_{epoch}_{currentTime}.png")
    plt.show()

def VisualizeAvgLoss(lossArr, folder, epoch, generator = True, SAVE = True, windowSize=5):
    x=(range(0,len(lossArr)))
    
    averageY = []
    sum = np.sum(lossArr[0:windowSize-1])
    for ind in range(len(lossArr) - windowSize + 1):
        sum+=lossArr[ind+windowSize-1]
        averageY.append(sum/windowSize)
        sum-=lossArr[ind]
        
    for ind in range(windowSize - 1):
        averageY.insert(0, np.nan)
        
    plt.figure(figsize = (12,10))
    plt.plot(x,averageY)
    str = "Discriminator"
    if generator:
        str = "Generator"
        
    plt.xlabel("Number of Iterations")
    plt.ylabel(str + " Loss")
    if SAVE:
        now = datetime.now()
        currentTime = now.strftime("%H:%M:%S")
        plt.savefig(folder + f"/{str}_Average_Loss_After_Epoch_{epoch}_WindowSize_{windowSize}_{currentTime}.png")
    plt.show()

"""## Step 6. Initializing The Model

### Defining Some Hyperparameters
"""

LEARNING_RATE = 2e-4
EPOCHS = 950
LAMBDA = 100 #Discriminator L1 Loss Hyperparameter as Defined in the Paper 
epoch = 1
BETAS = (0.5,0.999) #Optimizer Hyperparameter as Defined in the Paper
lossOfDiscriminator = []
lossOfGenerator = []

"""### Functions and Logic for Loading and Saving Checkpoints"""

inputFolder = "/content/drive/MyDrive/ProjectInput"
outputFolder = "/content/drive/MyDrive/ProjectOutputs"
checkpointPathDiscriminator = inputFolder+"/disc.pth.tar"
checkpointPathGenerator = inputFolder+"/gen.pth.tar"
loadModel = True

def SaveCheckpoint(model, optimizer, epoch, filename):
    print("=> Saving checkpoint")
    checkpoint = {
        "state_dict": model.state_dict(),
        "optimizer": optimizer.state_dict(),
        "epoch":epoch,
        "DISC_LOSS" : lossOfDiscriminator,
        "GEN_LOSS" : lossOfGenerator
    }
    torch.save(checkpoint, filename)

def LoadCheckpoint(checkpoint_file, model, optimizer, lr):
    print("=> Loading checkpoint")
    checkpoint = torch.load(checkpoint_file, map_location=device)
    model.load_state_dict(checkpoint["state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer"])
    global epoch
    global lossOfDiscriminator
    global lossOfGenerator
    epoch = checkpoint["epoch"]
    lossOfDiscriminator = checkpoint["DISC_LOSS"].copy()
    lossOfGenerator = checkpoint["GEN_LOSS"].copy()

    for param_group in optimizer.param_groups:
        param_group["lr"] = lr

"""### Initializing Models"""

discModel = Discriminator(3).to(device)
genModel = Generator(1).to(device)
optimizerForDiscriminator = optim.Adam(discModel.parameters(),lr=LEARNING_RATE, betas=BETAS)
optimizerForGenerator = optim.Adam(genModel.parameters(),lr=LEARNING_RATE, betas=BETAS)
LossFunction = nn.BCEWithLogitsLoss()
L1Loss = nn.L1Loss()
#Float 16 Training for faster Training
discriminatorScaler = torch.cuda.amp.GradScaler()
generatorScaler = torch.cuda.amp.GradScaler()

"""### Loading Previously Saved Checkpoint if Applicable"""

if loadModel:
    LoadCheckpoint(checkpointPathGenerator, genModel, optimizerForGenerator, LEARNING_RATE)
    LoadCheckpoint(checkpointPathDiscriminator, discModel, optimizerForDiscriminator, LEARNING_RATE)

SaveModel = True
checkpointPathDiscriminator = outputFolder+"/disc.pth.tar"
checkpointPathGenerator = outputFolder+"/gen.pth.tar"

"""## Step 7. Training"""

def TrainFunction(discModel, genModel, loader, optimizerForDiscriminator, optimizerForGenerator, L1Loss, BCELoss, generatorScaler, discriminatorScaler):
    loop = tqdm(loader, leave=True)
    for idx, (L, ab) in enumerate(loop):
        L = L.to(device)
        ab = ab.to(device)
        
        # Train Discriminator
        with torch.cuda.amp.autocast():
            YGenerated = genModel(L)
            discReal = discModel(torch.concat([L, ab],1))
            discRealLoss = BCELoss(discReal, torch.ones_like(discReal))
            discGenerated = discModel(torch.concat([L, YGenerated.detach()],1))
            discGeneratedLoss = BCELoss(discGenerated, torch.zeros_like(discGenerated))
            discriminatorLoss = (discRealLoss + discGeneratedLoss) / 2
            lossOfDiscriminator.append(discriminatorLoss.item())
        discModel.zero_grad()
        discriminatorScaler.scale(discriminatorLoss).backward()
        discriminatorScaler.step(optimizerForDiscriminator)
        discriminatorScaler.update()
        
        # Train generator
        with torch.cuda.amp.autocast():
            discGenerated = discModel(torch.concat([L, YGenerated],1))
            genGeneratedLoss = BCELoss(discGenerated, torch.ones_like(discGenerated))
            L1 = L1Loss(YGenerated, ab) * LAMBDA
            generatorLoss = genGeneratedLoss + L1
            lossOfGenerator.append(generatorLoss.item())

        optimizerForGenerator.zero_grad()
        generatorScaler.scale(generatorLoss).backward()
        generatorScaler.step(optimizerForGenerator)
        generatorScaler.update()

TRAIN=True 
visualizeWhileTraining=True
saveImages = True #To Save Images during visualization

while TRAIN and (epoch <= EPOCHS):
    print("\nEpoch",epoch,'\n')
    
    if visualizeWhileTraining:
        ShowSamples(genModel, validationDL,outputFolder,epoch,saveImages)
        
        print("Generator Loss\n")
        VisualizeLoss(lossOfGenerator,outputFolder,epoch,True,saveImages)
        print("Discriminator Loss\n")
        VisualizeLoss(lossOfDiscriminator,outputFolder,epoch,False,saveImages)
        
    if SaveModel:
        SaveCheckpoint(genModel, optimizerForGenerator, epoch, filename=checkpointPathGenerator)
        SaveCheckpoint(discModel, optimizerForDiscriminator, epoch, filename=checkpointPathDiscriminator)

    TrainFunction(discModel, genModel, trainDL, optimizerForDiscriminator, optimizerForGenerator, L1Loss, LossFunction, discriminatorScaler, generatorScaler)
    
    epoch+=1

"""## Step 8. Visualizing Loss Trajectory

### Generator Loss

#### Average Loss
"""

VisualizeAvgLoss(lossArr=lossOfGenerator,folder=outputFolder,epoch=epoch,generator=True,SAVE=True,windowSize=100)

"""#### Actual Loss"""

VisualizeLoss(lossArr=lossOfGenerator,folder=outputFolder,epoch=epoch,generator=True,SAVE=True)

"""### Discriminator Loss

#### Average Loss
"""

VisualizeAvgLoss(lossArr=lossOfDiscriminator,folder=outputFolder,epoch=epoch,generator=False,SAVE=True,windowSize=1000)

"""#### Actual Loss"""

VisualizeLoss(lossArr=lossOfDiscriminator,folder=outputFolder,epoch=epoch,generator=False,SAVE=True)

"""## Step 9. Visualizing Predictions

### Predictions on Training Data
"""

numRuns = 200 #Generate numRuns*5 Samples

for run in range(numRuns):
    ShowSamples(genModel, trainDL,outputFolder,epoch,SAVE=True,suffix="_On_Training_Set")

"""### Predictions on Validation Data"""

for run in range(numRuns):
    ShowSamples(genModel, validationDL,outputFolder,epoch,SAVE=True, suffix="_On_Validation_set")

